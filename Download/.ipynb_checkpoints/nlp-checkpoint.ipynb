{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Natural language processing using TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*Natural language processing (NLP)* involves the analysis and extraction of meaningful information from natural language data, such as speech or text. This notebook demonstrates several *NLP* methods using the Python module *TextBlob* (https://textblob.readthedocs.io/en/dev/).\n",
    "\n",
    "We will look at the following analyses:\n",
    "Tokenization, Stemming, Noun phrase extraction, sentiment analysis, word count analysis, and language translation powered by Google Translate.\n",
    "\n",
    "To use TextBlob, you must import it (see below), and then create a *TextBlob* object. By convention the *TextBlob* object is stored in a variable named *blob*, as in the example below:\n",
    "\n",
    "```python\n",
    "blob = TextBlob('text to analyze')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the world's a stage, and every word a note.\n",
      "And every day is filled with songs you never knew you wrote.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"All the world's a stage, and every word a note.\\nAnd every day is filled with songs you never knew you wrote.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Triple quotes are used to denote a multi-line string\n",
    "# Quote from Jude Christodal\n",
    "stage = \"\"\"All the world's a stage, and every word a note.\n",
    "And every day is filled with songs you never knew you wrote.\"\"\"\n",
    "\n",
    "# printing stage will output across multiple lines\n",
    "print(stage)\n",
    "\n",
    "# viewing the string we can see the newline ('\\n') characters\n",
    "stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to install packages on macbook, go to terminal\n",
    "#activate anaconda with\n",
    "#\"conda activate\"\n",
    "#Then install textblob\n",
    "#\"pip install textblob\"\n",
    "#Now you can import it on jupyter notebook\n",
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"All the world's a stage, and every word a note.\n",
       "And every day is filled with songs you never knew you wrote.\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a TextBlob object\n",
    "from textblob import TextBlob\n",
    "blob = TextBlob(stage)\n",
    "blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "*Tokenization* is the process of splitting text into meaningful pieces (sequences of characters), such as words or sentences. In general, these  pieces are referred to as tokens. TextBlob will automatically parse text into words and sentences. \n",
    "\n",
    "*TextBlob* objects contain many properties (or fields) that can be accessed using the dot ('.') operator. \n",
    "\n",
    "In particular for tokenization, for a *TextBlob* object named *blob*,\n",
    "\n",
    "- *blob.words* returns a list of *words*, stored in a WordList object that behaves like an ordinary *list*\n",
    "- *blob.sentences* returns a list of sentences, stored as a list of Sentence objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\villegasj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['All', 'the', 'world', \"'s\", 'a', 'stage', 'and', 'every', 'word', 'a', 'note', 'And', 'every', 'day', 'is', 'filled', 'with', 'songs', 'you', 'never', 'knew', 'you', 'wrote'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of words\n",
    "blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blob.words)\n",
    "blob.words[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Exercise\n",
    "How many words are there? What is the first word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blob.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"All the world's a stage, and every word a note.\"),\n",
       " Sentence(\"And every day is filled with songs you never knew you wrote.\")]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of sentences\n",
    "blob.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Note**: Each sentence has all the properties of a *TextBlob* object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['All', 'the', 'world', \"'s\", 'a', 'stage', 'and', 'every', 'word', 'a', 'note'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get first sentence\n",
    "sentence1 = blob.sentences[0]\n",
    "\n",
    "# Since sentence1 is like a TextBlob, we can get its words using the following\n",
    "sentence1.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Part of speech tagging\n",
    "\n",
    "*TextBlob* automatically carries out part-of-speech tagging, as shown below. The *tags* property includes a list of tuples in the form (word, part of speech). Common tags include *NN* for noun (singular or mass), *NNS* for noun (plural), and *VBN*, *VBZ*, and *VB* which are different types of verbs. For a list of tags, see https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\villegasj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('All', 'PDT'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('a', 'DT'),\n",
       " ('stage', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('every', 'DT'),\n",
       " ('word', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('note', 'NN'),\n",
       " ('And', 'CC'),\n",
       " ('every', 'DT'),\n",
       " ('day', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('filled', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('songs', 'NNS'),\n",
       " ('you', 'PRP'),\n",
       " ('never', 'RB'),\n",
       " ('knew', 'VBD'),\n",
       " ('you', 'PRP'),\n",
       " ('wrote', 'VBD')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('All', 'PDT')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Exercise\n",
    "Print out all of the nouns (which have tags of 'NN', or 'NNS', 'NNP', or 'NNPS'; no other part of speech contains an 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world\n",
      "stage\n",
      "word\n",
      "note\n",
      "day\n",
      "songs\n"
     ]
    }
   ],
   "source": [
    "for word, pos in blob.tags:\n",
    "    \n",
    "    #if word is a noun\n",
    "   # if pos == 'nn':\n",
    "    # If a word contains nn\n",
    "    if 'NN' in pos:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of all the nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['world', 'stage', 'word', 'note', 'day', 'songs']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = []\n",
    "\n",
    "for word, pos in blob.tags:\n",
    "    if 'NN' in pos:\n",
    "        nouns.append(word)\n",
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['world', 'stage', 'word', 'note', 'day', 'songs']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = [ word        for word, pos,             in blob.tags        if 'NN' in pos            ]\n",
    "\n",
    "nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Noun phrase extraction\n",
    "\n",
    "*Noun phrase extraction* involves the identification of *noun phrases*, which are phrases that include nouns (possibly following one or more adjectives)\n",
    "\n",
    "For a *TextBlob* object named *blob*, a list of noun phrases are returned using *blob.noun_phrases*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\villegasj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['amy', 'new red car'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob('Amy has a new red car')\n",
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Sentiment analysis\n",
    "\n",
    "A *sentiment analysis* measures the emotional content of text. We will use sentiment analysis to identify text as *positive* or *negative*, though other emotions can also be detected.\n",
    "\n",
    "For a *TextBlob* object named *blob*, its sentiment can be found by using *blob.sentiment*, which will give you a Sentiment object (a named tuple) that contains the following:\n",
    "\n",
    "- polarity: a score between -1 (negative sentiment) and +1 (positive sentiment)\n",
    "- subjectivity: a score between 0 (objective) and +1 (subjective)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.5, subjectivity=0.6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob('I love this class')\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.375, subjectivity=0.3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob('This class sucks!')\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.2828125, subjectivity=0.57)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the sentiment of a text blob will represent an average sentiment over multiple sentiments\n",
    "blob = TextBlob('This class is great. This class is awesome. This class sucks. This class sucks!!! This class is okay.')\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"This class is great.\" has a polarity of 0.8\n",
      "\"This class is awesome.\" has a polarity of 1.0\n",
      "\"This class sucks.\" has a polarity of -0.3\n",
      "\"This class sucks!!!\" has a polarity of -0.5859375\n",
      "\"This class is okay.\" has a polarity of 0.5\n"
     ]
    }
   ],
   "source": [
    "# but we can find the polarity of each sentence\n",
    "for s in blob.sentences:\n",
    "    print('\"', s, '\" has a polarity of ', s.sentiment.polarity, sep = '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Stemming \n",
    "\n",
    "*Stemming* is a normalization method that takes a word and converts it into a *base* form by removing word endings (suffixes) or prefixes.\n",
    "\n",
    "For a *TextBlob* word object, you can get the *stem* by calling *word.stem()*.\n",
    "\n",
    "Lemmatization is a related technique that takes the word's part of speech into account and returns a dictionary form of the word.\n",
    "\n",
    "Stemming and lemmatization are useful for counting words, since different forms of the same word (like 'runs' and 'run' should probably be counted as one word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run: run\n",
      "runs: run\n",
      "running: run\n",
      "ran: ran\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob('run runs running ran')\n",
    "\n",
    "# get word stems\n",
    "for w in blob.words :\n",
    "    print(w, ': ', w.stem(), sep = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Word counts\n",
    "\n",
    "Word counts are automatically calculated when a *TextBlob* object is created. The word counts of a *TextBlob* named *blob* are stored in *blob.word_counts*, which is a default dictionary (a dictionary where keys that do not exist have a default value, which in this case is 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'so': 1,\n",
       "             'get': 2,\n",
       "             'out': 1,\n",
       "             'your': 1,\n",
       "             'seat': 1,\n",
       "             'and': 2,\n",
       "             'jump': 5,\n",
       "             'around': 3,\n",
       "             'up': 2,\n",
       "             'down': 1})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Song lyrics by House of Pain\n",
    "jump = 'So get out your seat and jump around! Jump around! Jump around! Jump up, jump up and get down!'\n",
    "blob = TextBlob(jump)\n",
    "blob.word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "How many times does 'jump' appear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.word_counts['jump']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Because word_counts is a default dictionary, looking up a word not in the dictionary will return 0, and also add the word to the dictionary! Note: we could remove a key from a dictionary *d* by using *d.pop(key)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.word_counts['cheese']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can iterate through the keys of a dictionary using a for loop (*for keys in dict*). We also can iterate through key,value pairs of a dictionary by using *dictionary.items()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so: 1\n",
      "get: 2\n",
      "out: 1\n",
      "your: 1\n",
      "seat: 1\n",
      "and: 2\n",
      "jump: 5\n",
      "around: 3\n",
      "up: 2\n",
      "down: 1\n",
      "cheese: 0\n"
     ]
    }
   ],
   "source": [
    "for word, count in blob.word_counts.items() :\n",
    "    print(word, ': ', count, sep = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Stopwords\n",
    "\n",
    "Stopwords are common words (like 'a' and 'the') that should be ignored when analyzing text.\n",
    "\n",
    "We can get a list of stopwords from the *nltk.corpus*, using the function *stopwords.words()*. We convert this list to a *set*, which is a collection of unordered items (i.e., it is *not* a sequence). The advantage of a set is that it has a constant lookup time, meaning that it is faster to test whether an item is in a set than testing when an item is in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\villegasj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a set of stopwords\n",
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Removing stop words\n",
    "\n",
    "List comprehension can be used to create a list of (word, frequency) tuples with stop words removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('get', 2), ('seat', 1), ('jump', 5), ('around', 3), ('cheese', 0)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of (word, frequency) tuples but with stop words removed\n",
    "words = [ (w, f) for w,f in blob.word_counts.items() if w not in sw]\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Sorting by frequency\n",
    "\n",
    "The following code will return a sorted list, where the sorting is based on reading list elements from left to right.\n",
    "```python\n",
    "sorted(listName)\n",
    "```\n",
    "\n",
    "If the lists contains tuples, then sorting will be based on the first element of each tuple. But sometimes we want to sort based on another element. This is accomplished by specifying the *key* argument to the *sorted* function. An *itemgetter* can be used here to specify the *index* to use for sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jump', 5), ('around', 3), ('get', 2), ('seat', 1), ('cheese', 0)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the list\n",
    "from operator import itemgetter\n",
    "\n",
    "# sort the word list by frequency (stored in index 1 of each tuple) in reverse order (highest to lowest)\n",
    "words = sorted(words, key = itemgetter(1), reverse=True)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Generating a bar graph of word frequencies\n",
    "\n",
    "A *bar graph* visualizes word frequencies by using a bar for each word; the height of the bar corresponds to the frequency of the word. \n",
    "\n",
    "In order to create a bar graph, we first create a data frame (a table) of word frequencies. The *pandas* module is used to create the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jump</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>around</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  frequency\n",
       "0    jump          5\n",
       "1  around          3\n",
       "2     get          2\n",
       "3    seat          1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a data frame from a list of tuples (each element will be a column)\n",
    "df = pd.DataFrame(words, columns = ['word', 'frequency'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can then create a bar graph directly from the data frame, using pandas *plot.bar* function. Note that a *None* is included at the end the cell to prevent the cell from displaying the value returned by the *ax.set_title* statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3+ 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "3+7 \n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate a bar graph, where 'x' and 'y' are the data frame columns to use\n",
    "ax = df.plot.bar(x = 'word', y = 'frequency', legend = False, color = 'lightblue')\n",
    "\n",
    "# add y-axis labels and a title\n",
    "ax.set_ylabel('frequency')\n",
    "ax.set_title('Word Counts')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Because we looked up 'cheese' previously, this was added to the dictionary. How can we update the words list of tuples to remove (word, frequency) pairs where the frequency was 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jump', 5), ('around', 3), ('get', 2), ('seat', 1)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words\n",
    "# w = word\n",
    "# f = frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "words  = [  (w,f)  for w, f in words if f > 0   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jump', 5), ('around', 3), ('get', 2), ('seat', 1)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can generate a horizontal bar graph using the 'plot.barh' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df.plot.barh(x = 'word', y = 'frequency', legend = False)\n",
    "ax.set_xlabel('frequency')\n",
    "ax.set_title('Word Counts')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Word clouds\n",
    "\n",
    "A *word cloud* is a visualization of words where the size of each word is proportional to its frequency. Word clouds can be generated directly from text or from a dictionary containing words and their corresponding frequencies.\n",
    "\n",
    "The default WordCloud has the following arguments:\n",
    "\n",
    "```python\n",
    "WordCloud(background_color = 'black', stopwords = None, colormap = 'viridis', ...)\n",
    "```\n",
    "\n",
    "The *stopwords* argument can be a set of strings of stop words to remove; the default value of *None* will use a built-in stopwords list.\n",
    "\n",
    "For additional colormaps see https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\VILLEG~1\\AppData\\Local\\Temp/ipykernel_620/3810367571.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# generate a word cloud from text (stop words will be removed)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjump\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwordcloud\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "# generate a word cloud from text (stop words will be removed)\n",
    "wordcloud = WordCloud().generate(jump)\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WordCloud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\VILLEG~1\\AppData\\Local\\Temp/ipykernel_620/3570665880.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# generate a word cloud from a dictionary of frequencies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwordcloud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolormap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'prism'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mwordcloud\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'WordCloud' is not defined"
     ]
    }
   ],
   "source": [
    "# generate a word cloud from a dictionary of frequencies\n",
    "wordcloud = WordCloud(colormap = 'prism').generate_from_frequencies(blob.word_counts)\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Language translation\n",
    "\n",
    "TextBlob can use Google Translate's API (Application Programming Interface) to detect the language of text and to translate between a variety of languages. \n",
    "\n",
    "The supported languages and abbreviations can be found here: https://cloud.google.com/translate/docs/languages\n",
    "\n",
    "When *TextBlob* is used for language detection or translation, a request is sent to Google Translate, which carries out the task and returns the result (an internet connection is therefore required). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Hola como estas?\")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new blob and detect the language\n",
    "blob = TextBlob('Hola como estas?')\n",
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Hi, how are you?\")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default translation will be to english (to='en')\n",
    "blob.translate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"\")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's translate this to Chinese (simplified)\n",
    "blob.translate(to='zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
